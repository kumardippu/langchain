import os

from langchain.schema import HumanMessage

try:
    from langchain_ollama import ChatOllama
    OLLAMA_AVAILABLE = True
except ImportError:
    print("âŒ Ollama package not installed. Install with: pip install langchain-ollama")
    OLLAMA_AVAILABLE = False

if OLLAMA_AVAILABLE:
    print("ğŸ¦™ Ollama - Free Local AI Models")
    print("=" * 50)
    print("ğŸ“‹ Available models:")
    print("1. llama3.2 (3B) - Fast and lightweight")
    print("2. llama3.2 (1B) - Very fast, basic tasks")
    print("3. qwen2.5 (7B) - Good for coding")
    print("4. mistral (7B) - General purpose")
    
    print("\nğŸ’¡ First time? Install Ollama from: https://ollama.ai")
    print("ğŸ’¡ Then run: ollama pull llama3.2")
    
    # Initialize the model
    try:
        model = ChatOllama(
            model="llama3.2",  # 3B model - good balance of speed/quality
            temperature=0.7
        )
        
        print("\nâœ… Ollama model loaded successfully!")
        print("=" * 50)
        
        while True:
            question = input("\nğŸ’¬ Ask me anything (or 'quit' to exit): ")
            
            if question.lower() in ['quit', 'exit', 'q']:
                print("ğŸ‘‹ Goodbye!")
                break
                
            if not question.strip():
                continue

            # Get response from AI
            print("\nğŸ¦™ Thinking locally...")
            try:
                response = model.invoke([HumanMessage(content=question)])
                print(f"\nğŸ¤– Llama: {response.content}")
            except Exception as e:
                print(f"âŒ Error: {e}")
                print("ğŸ’¡ Make sure Ollama is running and the model is installed")
                print("ğŸ’¡ Try: ollama serve (in another terminal)")
                print("ğŸ’¡ Then: ollama pull llama3.2")
            
            print("\n" + "=" * 50)
            
    except Exception as e:
        print(f"âŒ Failed to initialize Ollama: {e}")
        print("ğŸ’¡ Make sure Ollama is installed and running")
else:
    print("Install Ollama: pip install langchain-ollama")
